{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d3d3e0e",
      "metadata": {
        "id": "7d3d3e0e"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi uvicorn pyngrok transformers --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1833afb",
      "metadata": {
        "id": "f1833afb"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, UploadFile, File ,Request\n",
        "from fastapi.responses import JSONResponse\n",
        "from pydantic import BaseModel\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from transformers import (\n",
        "    AutoModelForTokenClassification, AutoTokenizer, TokenClassificationPipeline,\n",
        "    AutoModelForSequenceClassification, TextClassificationPipeline\n",
        ")\n",
        "import torch\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "import json\n",
        "\n",
        "nest_asyncio.apply()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x55HA91SPWtR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x55HA91SPWtR",
        "outputId": "792559af-d241-4fee-82be-1926ea292d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "ngrok.set_auth_token(\"2z9U0xaAKf5QWl10rKPg2xVQEVo_6EcE5gViQAwkcbcdP73iS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "So8D4-IAPsi-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So8D4-IAPsi-",
        "outputId": "6b234eb1-62f2-4501-8cf9-4a28b0cf46fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6a701a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee6a701a",
        "outputId": "5198715d-3ae9-4576-db57-ea0ba30f1026"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "aspect_model_path = \"/content/drive/MyDrive/absa_model/aspect_extractor/\"\n",
        "sentiment_model_path = \"/content/drive/MyDrive/absa_model/sentiment_classifier/\"\n",
        "\n",
        "# Load aspect extractor\n",
        "aspect_model = AutoModelForTokenClassification.from_pretrained(aspect_model_path)\n",
        "aspect_tokenizer = AutoTokenizer.from_pretrained(aspect_model_path)\n",
        "aspect_pipeline = TokenClassificationPipeline(\n",
        "    model=aspect_model,\n",
        "    tokenizer=aspect_tokenizer,\n",
        "    aggregation_strategy=None,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "# Load sentiment classifier\n",
        "sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_path)\n",
        "sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_path)\n",
        "sentiment_pipeline = TextClassificationPipeline(\n",
        "    model=sentiment_model,\n",
        "    tokenizer=sentiment_tokenizer,\n",
        "    return_all_scores=False,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b08bb95",
      "metadata": {
        "id": "7b08bb95"
      },
      "outputs": [],
      "source": [
        "def extract_aspects(sentence: str):\n",
        "    predictions = aspect_pipeline(sentence)\n",
        "    aspects = []\n",
        "    current_aspect = \"\"\n",
        "    current_scores = []\n",
        "\n",
        "    for pred in predictions:\n",
        "        token = pred['word']\n",
        "        label = pred['entity']\n",
        "        score = pred['score']\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            token = token[2:]\n",
        "            current_aspect += token\n",
        "            current_scores.append(score)\n",
        "        else:\n",
        "            if label == \"B-ASP\":\n",
        "                if current_aspect:\n",
        "                    avg_score = float(sum(current_scores) / len(current_scores))\n",
        "                    aspects.append((current_aspect.strip(), avg_score))\n",
        "                current_aspect = token\n",
        "                current_scores = [score]\n",
        "            elif label == \"I-ASP\":\n",
        "                current_aspect += \" \" + token\n",
        "                current_scores.append(score)\n",
        "            else:\n",
        "                if current_aspect:\n",
        "                    avg_score = float(sum(current_scores) / len(current_scores))\n",
        "                    aspects.append((current_aspect.strip(), avg_score))\n",
        "                    current_aspect = \"\"\n",
        "                    current_scores = []\n",
        "    if current_aspect:\n",
        "        avg_score = float(sum(current_scores) / len(current_scores))\n",
        "        aspects.append((current_aspect.strip(), avg_score))\n",
        "    return aspects\n",
        "\n",
        "def predict_sentiment(sentence: str, aspects: list):\n",
        "    results = []\n",
        "    for aspect, asp_score in aspects:\n",
        "        model_input = f\"{aspect} </s> {sentence}\"\n",
        "        pred = sentiment_pipeline(model_input)[0]\n",
        "        results.append({\n",
        "            \"aspect\": aspect,\n",
        "            \"aspect_score\": round(float(asp_score), 2),\n",
        "            \"sentiment\": pred[\"label\"],\n",
        "            \"confidence\": round(float(pred[\"score\"]), 2)\n",
        "        })\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe19942",
      "metadata": {
        "id": "dfe19942"
      },
      "outputs": [],
      "source": [
        "app = FastAPI()\n",
        "\n",
        "class SentenceRequest(BaseModel):\n",
        "    sentence: str\n",
        "\n",
        "@app.post(\"/predict-text\")\n",
        "async def predict_text(data: SentenceRequest):\n",
        "    aspects = extract_aspects(data.sentence)\n",
        "    sentiments = predict_sentiment(data.sentence, aspects)\n",
        "    return sentiments\n",
        "\n",
        "@app.post(\"/predict-file\")\n",
        "async def predict_file(request: Request):\n",
        "    data = await request.json()\n",
        "    comments = data.get(\"comments\")\n",
        "    print(comments)\n",
        "    if not comments or not isinstance(comments, list):\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Expecting JSON with 'comments' list.\"})\n",
        "\n",
        "    all_results = []\n",
        "    for sentence in comments:\n",
        "        aspects = extract_aspects(sentence)\n",
        "        sentiments = predict_sentiment(sentence, aspects)\n",
        "        all_results.append({\"sentence\": sentence, \"aspects\": sentiments})\n",
        "    return {\"results\": all_results}  # retourne dict avec \"results\" clÃ©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86fd764c",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "86fd764c",
        "outputId": "01c4583f-5e5d-488d-d9f8-4d98ded405b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ L'API est disponible Ã  l'adresse : NgrokTunnel: \"https://fa33-34-169-230-61.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [243]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     196.75.164.13:0 - \"POST /predict-text HTTP/1.1\" 200 OK\n",
            "['The food was excellent and the waiter was very attentive.', 'I loved the ambiance but the service was slow.', 'The desserts were delicious but the main course was disappointing.', 'The staff was rude and the place was noisy.', 'The location is perfect but parking is difficult.', 'The restaurant was clean and the tables were nicely arranged.', 'I had a great time, especially enjoying the live music.', 'The prices are reasonable but the portions are small.', 'The chef prepared the steak exactly how I like it.', 'The waiting time was too long and the hostess was unfriendly.', 'The drinks were refreshing and well prepared.', 'I did not like the salad; it was too salty.', 'The seafood platter was fresh and tasty.', 'The waiter forgot our order twice, which was frustrating.', 'The view from the terrace is breathtaking, perfect for dinner.']\n",
            "INFO:     196.75.164.13:0 - \"POST /predict-file HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "# Lancer le serveur en arriÃ¨re-plan\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"ðŸš€ L'API est disponible Ã  l'adresse :\", public_url)\n",
        "\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "U1RnKA5HOPGD",
      "metadata": {
        "id": "U1RnKA5HOPGD"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}